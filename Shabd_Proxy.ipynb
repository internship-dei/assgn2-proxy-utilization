{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shabd_Proxy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rHTgUzERWJi"
      },
      "source": [
        "#Stats and Observations\n",
        "\n",
        "Total Proxy Used : 100\n",
        "\n",
        "Total Proxy with Request code 200 : 91\n",
        "\n",
        "Total Proxy with Connection Error : 9\n",
        "\n",
        "Percentage Successful : 91%\n",
        "\n",
        "URL used :  https://www.techradar.com/in/vpn/best-free-vpn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWPKu1hmDmXG"
      },
      "source": [
        "import requests\n",
        "from lxml.html import fromstring\n",
        "URL = ['https://free-proxy-list.net/#','https://free-proxy-list.net/#','https://free-proxy-list.net/#','https://free-proxy-list.net/#','https://free-proxy-list.net/#']\n",
        "for url in range(0,5):\n",
        " def get_proxies():\n",
        "   urls = URL[url]\n",
        "   response = requests.get(urls)\n",
        "   parser = fromstring(response.text)\n",
        "   proxies = set()\n",
        "   for i in parser.xpath('//tbody/tr')[:100000]:\n",
        "     if i.xpath('.//td[7][contains(text(),\"yes\")]'):\n",
        "      proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
        "      proxies.add(proxy)\n",
        "   return proxies\n",
        "\n",
        "proxies = get_proxies()\n",
        "print(proxies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JabuqeOeI3lF"
      },
      "source": [
        "import requests\n",
        "from itertools import cycle\n",
        "import traceback\n",
        "from bs4 import BeautifulSoup\n",
        "proxies = get_proxies()\n",
        "proxy_pool = cycle(proxies)\n",
        "url = 'https://www.techradar.com/in/vpn/best-free-vpn'\n",
        "for i in range(1,56):\n",
        " proxy = next(proxy_pool)\n",
        " print(\"Request #%d\"%i)\n",
        " try:\n",
        "  response = requests.get(url,proxies={\"http\": proxy, \"https\": proxy})\n",
        "  print(response)\n",
        " except:\n",
        "  print(\"Skipping. Connnection error\")\n",
        "soup = BeautifulSoup(page.content, \"html.parser\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqkcmn6EGKjh"
      },
      "source": [
        "soup.title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_ptbGqaGLQ5"
      },
      "source": [
        "all_text = []\n",
        "for text in soup.find_all('p'):\n",
        "   all_text.append(text.getText())\n",
        "all_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVgB6_ySGNWy"
      },
      "source": [
        "h_list = []\n",
        "headings = ['h1','h2','h3','h4']\n",
        "for h in soup.find_all(headings):\n",
        "  h_list.append(h.getText())\n",
        "h_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZzy--F8GRpC"
      },
      "source": [
        "th_list = []\n",
        "for h in soup.find_all('th'):\n",
        "  th_list.append(h.getText())\n",
        "th_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGunLNuUGV0g"
      },
      "source": [
        "td_list = []\n",
        "for h in soup.find_all('td'):\n",
        "  td_list.append(h.getText().strip().split('\\n'))\n",
        "td_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpM540esGYej"
      },
      "source": [
        "tr_list = []\n",
        "for tr in soup.find_all('tr'):\n",
        "  for a in tr.find_all('a', href=True):\n",
        "    all_text = str(tr.getText().strip()+'\\n'+a['href'])\n",
        "    tr_list.append(all_text.split('\\n'))\n",
        "\n",
        "tr_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJU344qiGbwC"
      },
      "source": [
        "import pandas as pd\n",
        "th_list.append('URL')\n",
        "df_data = pd.DataFrame(tr_list, columns = th_list)\n",
        "df_data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}